{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import tensorflow as tf\n",
    "import joblib\n",
    "import os\n",
    "import time\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from time import time\n",
    "from statsmodels.tsa.stattools import kpss\n",
    "from plotnine import *\n",
    "\n",
    "# Load the datasets\n",
    "chýbajúci_zub = pd.read_csv('missing_tooth.csv')\n",
    "odštiepený_zub = pd.read_csv('tooth_chipped_fault.csv')\n",
    "povrchová_chyba = pd.read_csv('surface_fault.csv')\n",
    "bez_poruchy = pd.read_csv('no_fault.csv')\n",
    "koreňová_trhlina = pd.read_csv('root_crack.csv')\n",
    "výstrednosť = pd.read_csv('eccentricity.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chýbajúci_zub['state'] = 'chýbajúci_zub'\n",
    "odštiepený_zub['state'] = 'odštiepený_zub'\n",
    "povrchová_chyba['state'] = 'povrchová_chyba'\n",
    "bez_poruchy['state'] = 'bez_poruchy'\n",
    "koreňová_trhlina['state'] = 'koreňová_trhlina'\n",
    "výstrednosť['state'] = 'výstrednosť'\n",
    "\n",
    "df = pd.concat([\n",
    "    bez_poruchy,\n",
    "    chýbajúci_zub, \n",
    "    odštiepený_zub,\n",
    "    povrchová_chyba,\n",
    "    koreňová_trhlina, \n",
    "    výstrednosť\n",
    "])\n",
    "\n",
    "#Normalize time_x grouped by state, load_value, speedSet\n",
    "df['time_x'] = pd.to_datetime(df['time_x'])\n",
    "df['time_normalized'] = df.groupby(['state', 'load_value', 'speedSet'])['time_x'].transform(lambda x: (x - x.min()).dt.total_seconds())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['formated_time'] = pd.to_datetime(df.time_x, format=\"%Y-%m-%d %H:%M:%S.%f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the variables before using them\n",
    "speedload_8_0 = df[(df['speedSet'] == 8.33203125) & (df['load_value'] == 0)].copy()\n",
    "speedload_8_80 = df[(df['speedSet'] == 8.33203125) & (df['load_value'] == 80)].copy()\n",
    "speedload_25_0 = df[(df['speedSet'] == 25) & (df['load_value'] == 0)].copy()\n",
    "speedload_25_80 = df[(df['speedSet'] == 25) & (df['load_value'] == 80)].copy()\n",
    "speedload_40_0 = df[(df['speedSet'] == 40) & (df['load_value'] == 0)].copy()\n",
    "speedload_40_80 = df[(df['speedSet'] == 40) & (df['load_value'] == 80)].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the KPSS test to each unique state for 'sensor1' values by 'normalized_time'.\n",
    "def apply_kpss(series):\n",
    "    kpss_stat, p_value, lags, crit = kpss(series, 'c')\n",
    "    return kpss_stat, p_value, crit\n",
    "\n",
    "# Apply the KPSS test to all unique states\n",
    "unique_states = speedload_8_0['state'].unique()\n",
    "kpss_results = {}\n",
    "for state in unique_states:\n",
    "    # Extracting the time series data for 'sensor1' for the current state\n",
    "    time_series = speedload_8_0.loc[speedload_8_0['state'] == state, 'sensor1']\n",
    "    # Applying KPSS test\n",
    "    kpss_stat, p_value, crit = apply_kpss(time_series)\n",
    "    kpss_results[state] = (kpss_stat, p_value, crit)\n",
    "\n",
    "# You can print out the results or convert it to a DataFrame\n",
    "kpss_results_df = pd.DataFrame(kpss_results, index=['KPSS Štatistica', 'p-hodnota', 'Kritické hodnoty']).T\n",
    "print(kpss_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotnine import *\n",
    "\n",
    "display(ggplot(data=speedload_8_0, mapping=aes(x='time_normalized', y='sensor2', color='state')) + geom_smooth() + \n",
    "        ggtitle('Rýchlosť 8.33/Záťaž 0') +\n",
    "        labs(x='Hodnoty snímač2', y='Čas', fill='Stav') +\n",
    "        theme(\n",
    "            figure_size=(10, 6),  # Width and height in inches\n",
    "            dpi=150,  # Set the resolution of the plot\n",
    "            axis_text=element_text(size=16),  # Axis tick labels\n",
    "            axis_title=element_text(size=18, weight='bold'),  # Axis titles\n",
    "            plot_title=element_text(size=20, weight='bold', ha='center'),  # Plot title\n",
    "            legend_title=element_text(size=16, weight='bold'),  # Legend title\n",
    "            legend_text=element_text(size=14, weight='bold')  # Legend text\n",
    "        ))\n",
    "display(ggplot(data=speedload_40_80, mapping=aes(x='time_normalized', y='sensor2', color='state')) + geom_smooth() + \n",
    "        ggtitle('Rýchlosť 40/Záťaž 80') +\n",
    "        labs(x='Hodnoty snímač2', y='Čas', fill='Stav') +\n",
    "        theme(\n",
    "            figure_size=(10, 6),  # Width and height in inches\n",
    "            dpi=150,  # Set the resolution of the plot\n",
    "            axis_text=element_text(size=16),  # Axis tick labels\n",
    "            axis_title=element_text(size=18, weight='bold'),  # Axis titles\n",
    "            plot_title=element_text(size=20, weight='bold', ha='center'),  # Plot title\n",
    "            legend_title=element_text(size=16, weight='bold'),  # Legend title\n",
    "            legend_text=element_text(size=14, weight='bold')  # Legend text\n",
    "        ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['#E41A1C', '#377EB8', '#4DAF4A', '#984EA3', '#FF7F00', '#FFFF33']\n",
    "\n",
    "display(ggplot(data=speedload_40_80, mapping=aes(x='sensor2', fill='state')) + geom_density(alpha=0.3) + stat_ecdf() +\n",
    "        scale_fill_manual(values=colors) + ggtitle('Rýchlosť 8.33/Záťaž 0') +\n",
    "        labs(x='Hodnoty snímač2', y='Hustota distribúcie', fill='Stav') + xlim(2.35, 2.5) +\n",
    "        theme(\n",
    "            figure_size=(10, 6),  # Width and height in inches\n",
    "            dpi=150,  # Set the resolution of the plot\n",
    "            axis_text=element_text(size=16),  # Axis tick labels\n",
    "            axis_title=element_text(size=18, weight='bold'),  # Axis titles\n",
    "            plot_title=element_text(size=20, weight='bold', ha='center'),  # Plot title\n",
    "            legend_title=element_text(size=16, weight='bold'),  # Legend title\n",
    "            legend_text=element_text(size=14, weight='bold')  # Legend text\n",
    "        ))\n",
    "display(ggplot(data=speedload_8_0, mapping=aes(x='sensor2', fill='state')) + geom_density(alpha=0.3) + stat_ecdf() +\n",
    "        scale_fill_manual(values=colors) + ggtitle('Rýchlosť 8.33/Záťaž 80') +\n",
    "        labs(x='Hodnoty snímač2', y='Hustota distribúcie', fill='Stav') + xlim(2.42, 2.436) +\n",
    "        theme(\n",
    "            figure_size=(10, 6),  # Width and height in inches\n",
    "            dpi=150,  # Set the resolution of the plot\n",
    "            axis_text=element_text(size=16),  # Axis tick labels\n",
    "            axis_title=element_text(size=18, weight='bold'),  # Axis titles\n",
    "            plot_title=element_text(size=20, weight='bold', ha='center'),  # Plot title\n",
    "            legend_title=element_text(size=16, weight='bold'),  # Legend title\n",
    "            legend_text=element_text(size=14, weight='bold')  # Legend text\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotnine import ggplot, aes, geom_point, facet_wrap, ggtitle\n",
    "# Plot state column sensor values as bez_poruchy against other '~bez_poruchy' values\n",
    "df_news = df.copy()\n",
    "df_news['state_group'] = df_news['state'].apply(lambda x: 'bez_poruchy' if x == 'bez_poruchy' else 'fault')\n",
    "display(ggplot(df_news, aes(x='sensor1', y='sensor2', color='state_group')) + geom_point(size=0.2) + facet_wrap('~state_group') + ggtitle('sensor1 vs sensor2 values for bez_poruchy and fault states'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example data setup (replace or adjust based on your actual dataframe 'df')\n",
    "df['state_expected'] = df.state.apply(lambda x: ['bez_poruchy', 'chýbajúci_zub', 'odštiepený_zub', 'povrchová_chyba', 'koreňová_trhlina', 'výstrednosť'].index(x))\n",
    "\n",
    "# Creating a dictionary for the transformation\n",
    "mapping_dict = df.set_index('state_expected')['state'].to_dict()\n",
    "\n",
    "# Correctly creating DataFrame from dictionary\n",
    "state_expected_keys = pd.DataFrame(list(mapping_dict.items()), columns=['state_expected', 'state'])\n",
    "display(state_expected_keys)\n",
    "# Creating a new DataFrame without certain columns\n",
    "df_edit = df[['sensor1', 'sensor2', 'speedSet', 'load_value', 'state_expected', 'time_normalized']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_edit['sample'] = df_edit.time_normalized < 4\n",
    "\n",
    "df_edit['sensor1_25_max'] = df_edit['sensor1'].rolling(window=25, min_periods=1).max()\n",
    "df_edit['sensor1_25_min'] = df_edit['sensor1'].rolling(window=25, min_periods=1).min()\n",
    "df_edit['sensor1_25_mean'] = df_edit['sensor1'].rolling(window=25, min_periods=1).mean()\n",
    "df_edit['sensor1_25_std'] = df_edit['sensor1'].rolling(window=25, min_periods=1).std()\n",
    "df_edit['sensor1_25_median'] = df_edit['sensor1'].rolling(window=25, min_periods=1).median()\n",
    "\n",
    "df_edit['sensor2_25_max'] = df_edit['sensor2'].rolling(window=25, min_periods=1).max()\n",
    "df_edit['sensor2_25_min'] = df_edit['sensor2'].rolling(window=25, min_periods=1).min()\n",
    "df_edit['sensor2_25_mean'] = df_edit['sensor2'].rolling(window=25, min_periods=1).mean()\n",
    "df_edit['sensor2_25_std'] = df_edit['sensor2'].rolling(window=25, min_periods=1).std()\n",
    "df_edit['sensor2_25_median'] = df_edit['sensor2'].rolling(window=25, min_periods=1).median()\n",
    "\n",
    "df_edit['sensor1_50_max'] = df_edit['sensor1'].rolling(window=50, min_periods=1).max()\n",
    "df_edit['sensor1_50_min'] = df_edit['sensor1'].rolling(window=50, min_periods=1).min()\n",
    "df_edit['sensor1_50_mean'] = df_edit['sensor1'].rolling(window=50, min_periods=1).mean()\n",
    "df_edit['sensor1_50_std'] = df_edit['sensor1'].rolling(window=50, min_periods=1).std()\n",
    "df_edit['sensor1_50_median'] = df_edit['sensor1'].rolling(window=50, min_periods=1).median()\n",
    "\n",
    "df_edit['sensor2_50_max'] = df_edit['sensor2'].rolling(window=50, min_periods=1).max()\n",
    "df_edit['sensor2_50_min'] = df_edit['sensor2'].rolling(window=50, min_periods=1).min()\n",
    "df_edit['sensor2_50_mean'] = df_edit['sensor2'].rolling(window=50, min_periods=1).mean()\n",
    "df_edit['sensor2_50_std'] = df_edit['sensor2'].rolling(window=50, min_periods=1).std()\n",
    "df_edit['sensor2_50_median'] = df_edit['sensor2'].rolling(window=50, min_periods=1).median()\n",
    "\n",
    "df_edit['sensor1_100_max'] = df_edit['sensor1'].rolling(window=100, min_periods=1).max()\n",
    "df_edit['sensor1_100_min'] = df_edit['sensor1'].rolling(window=100, min_periods=1).min()\n",
    "df_edit['sensor1_100_mean'] = df_edit['sensor1'].rolling(window=100, min_periods=1).mean()\n",
    "df_edit['sensor1_100_std'] = df_edit['sensor1'].rolling(window=100, min_periods=1).std()\n",
    "df_edit['sensor1_100_median'] = df_edit['sensor1'].rolling(window=100, min_periods=1).median()\n",
    "\n",
    "df_edit['sensor2_100_max'] = df_edit['sensor2'].rolling(window=100, min_periods=1).max()\n",
    "df_edit['sensor2_100_min'] = df_edit['sensor2'].rolling(window=100, min_periods=1).min()\n",
    "df_edit['sensor2_100_mean'] = df_edit['sensor2'].rolling(window=100, min_periods=1).mean()\n",
    "df_edit['sensor2_100_std'] = df_edit['sensor2'].rolling(window=100, min_periods=1).std()\n",
    "df_edit['sensor2_100_median'] = df_edit['sensor2'].rolling(window=100, min_periods=1).median()\n",
    "\n",
    "df_edit['sensor1_200_max'] = df_edit['sensor1'].rolling(window=200, min_periods=1).max()\n",
    "df_edit['sensor1_200_min'] = df_edit['sensor1'].rolling(window=200, min_periods=1).min()\n",
    "df_edit['sensor1_200_mean'] = df_edit['sensor1'].rolling(window=200, min_periods=1).mean()\n",
    "df_edit['sensor1_200_std'] = df_edit['sensor1'].rolling(window=200, min_periods=1).std()\n",
    "df_edit['sensor1_200_median'] = df_edit['sensor1'].rolling(window=200, min_periods=1).median()\n",
    "\n",
    "df_edit['sensor2_200_max'] = df_edit['sensor2'].rolling(window=200, min_periods=1).max()\n",
    "df_edit['sensor2_200_min'] = df_edit['sensor2'].rolling(window=200, min_periods=1).min()\n",
    "df_edit['sensor2_200_mean'] = df_edit['sensor2'].rolling(window=200, min_periods=1).mean()\n",
    "df_edit['sensor2_200_std'] = df_edit['sensor2'].rolling(window=200, min_periods=1).std()\n",
    "df_edit['sensor2_200_median'] = df_edit['sensor2'].rolling(window=200, min_periods=1).median()\n",
    "\n",
    "df_edit['sensor1_400_max'] = df_edit['sensor1'].rolling(window=400, min_periods=1).max()\n",
    "df_edit['sensor1_400_min'] = df_edit['sensor1'].rolling(window=400, min_periods=1).min()\n",
    "df_edit['sensor1_400_mean'] = df_edit['sensor1'].rolling(window=400, min_periods=1).mean()\n",
    "df_edit['sensor1_400_std'] = df_edit['sensor1'].rolling(window=400, min_periods=1).std()\n",
    "df_edit['sensor1_400_median'] = df_edit['sensor1'].rolling(window=400, min_periods=1).median()\n",
    "\n",
    "df_edit['sensor2_400_max'] = df_edit['sensor2'].rolling(window=400, min_periods=1).max()\n",
    "df_edit['sensor2_400_min'] = df_edit['sensor2'].rolling(window=400, min_periods=1).min()\n",
    "df_edit['sensor2_400_mean'] = df_edit['sensor2'].rolling(window=400, min_periods=1).mean()\n",
    "df_edit['sensor2_400_std'] = df_edit['sensor2'].rolling(window=400, min_periods=1).std()\n",
    "df_edit['sensor2_400_median'] = df_edit['sensor2'].rolling(window=400, min_periods=1).median()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Choose the data from train, test sets from 0 to 4 seconds and 4 to 5 seconds from time_normalized\n",
    "X_train = df_edit[(df_edit['time_normalized'] >= 0) & (df_edit['time_normalized'] < 4)].copy()\n",
    "X_test = df_edit[(df_edit['time_normalized'] >= 4) & (df_edit['time_normalized'] < 5)].copy()\n",
    "\n",
    "y_train = X_train['state_expected']\n",
    "y_test = X_test['state_expected']\n",
    "\n",
    "# Replace NaN values with 0\n",
    "X_train.fillna(0, inplace=True)\n",
    "X_test.fillna(0, inplace=True)\n",
    "\n",
    "# keep not standardized data in X_train_not_scaled, X_test_not_scaled, X_val_not_scaled\n",
    "X_train_not_scaled = X_train.copy()\n",
    "X_test_not_scaled = X_test.copy()\n",
    "\n",
    "# Replace NaN values with 0\n",
    "X_train.fillna(0, inplace=True)\n",
    "X_test.fillna(0, inplace=True)\n",
    "\n",
    "# Replace NaN values with 0\n",
    "X_train_not_scaled.fillna(0, inplace=True)\n",
    "X_test_not_scaled.fillna(0, inplace=True)\n",
    "\n",
    "# Drop column state_expected\n",
    "X_train.drop(columns=['state_expected', 'sample', 'time_normalized'], inplace=True)\n",
    "X_test.drop(columns=['state_expected', 'sample', 'time_normalized'], inplace=True)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "log_reg = LogisticRegression(max_iter=100, multi_class='ovr', C=0.1)\n",
    "log_reg.fit(X_train, y_train)\n",
    "start_time1 = time()\n",
    "y_pred = log_reg.predict(X_test)\n",
    "training_time = time() - start_time1\n",
    "\n",
    "accuracy_lr = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy_lr)\n",
    "\n",
    "# Save the model to a file\n",
    "model_name = f'logistic_regression_{accuracy_lr:.4f}'\n",
    "\n",
    "# Save the model\n",
    "model_directory = 'models'\n",
    "model_path = f'{model_directory}/{model_name}.h5'\n",
    "os.makedirs(model_directory, exist_ok=True)\n",
    "joblib.dump(log_reg, model_path)\n",
    "\n",
    "# Save the metadata\n",
    "metadata_path = f'{model_directory}/{model_name}_metadata.txt'\n",
    "with open(metadata_path, 'w') as f:\n",
    "    f.write(f\"Model Name: {model_name}\\n\")\n",
    "    f.write(f\"Accuracy: {accuracy_lr}\\n\")\n",
    "    f.write(f\"Training Time: {training_time} seconds\\n\")\n",
    "    f.write(f\"Hyperparameters: {log_reg.get_params()}\\n\")\n",
    "\n",
    "print(f\"Model and metadata saved in {model_directory}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_edit_viz = df_edit.copy()\n",
    "df_edit_viz.state_expected.astype(str).iloc[0]\n",
    "df_edit_viz['bez_poruchy'] = df_edit_viz['state_expected'] == 0\n",
    "\n",
    "plot = (ggplot(data=df_edit_viz[(df_edit_viz.speedSet == 8.33203125) & (df_edit_viz.load_value == 0)],\n",
    "               mapping=aes(x='sensor2_400_std', y='sensor1_400_std', color='bez_poruchy'))\n",
    "        + geom_point()\n",
    "        + facet_wrap('~bez_poruchy'))\n",
    "\n",
    "display(plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Trasnform classes from numerical to names using state_expected_keys\n",
    "log_reg.classes_ = state_expected_keys.state.values\n",
    "log_reg.classes_\n",
    "\n",
    "# Show confnusion matrix as a heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=log_reg.classes_, yticklabels=log_reg.classes_)\n",
    "plt.xlabel('Predikované')\n",
    "plt.ylabel('Aktuálne')\n",
    "plt.title('Konfúzna matica LogReg')\n",
    "plt.legend([f'Presnosť: {accuracy_lr:.2f}'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter grid for RandomizedSearch\n",
    "param_grid_lgbm = {\n",
    "    'num_leaves': [31],\n",
    "    'min_data_in_leaf': [20],\n",
    "    'max_depth': [-1],\n",
    "    'learning_rate': [0.01],\n",
    "    'n_estimators': [100]\n",
    "}\n",
    "\n",
    "lgb_model = lgb.LGBMClassifier()\n",
    "test_times = []\n",
    "time_start2 = time()\n",
    "# Grid search\n",
    "best_lgb_model = GridSearchCV(lgb_model, param_grid_lgbm, cv=4, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "best_lgb_model.fit(X_train, y_train)\n",
    "training_time = time() - time_start2\n",
    "best_lgb = best_lgb_model.best_estimator_\n",
    "time_test2 = time()\n",
    "# Predict the test set\n",
    "y_pred = best_lgb.predict(X_test)\n",
    "test_times.append(time() - time_test2)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy_lgb = accuracy_score(y_test, y_pred)\n",
    "display(print(\"Accuracy:\", accuracy_lgb))\n",
    "\n",
    "# Save the model to a file\n",
    "model_name = f'lightgbm_{accuracy_lgb:.4f}'\n",
    "model_directory = 'models'\n",
    "model_path = f'{model_directory}/{model_name}.h5'\n",
    "joblib.dump(best_lgb, model_path)\n",
    "\n",
    "# Save the metadata\n",
    "metadata_path = f'{model_directory}/{model_name}_metadata.txt'\n",
    "with open(metadata_path, 'w') as f:\n",
    "    f.write(f\"Model Name: {model_name}\\n\")\n",
    "    f.write(f\"Accuracy: {accuracy_lgb}\\n\")\n",
    "    f.write(f\"Training Time: {training_time} seconds\\n\")\n",
    "    f.write(f\"Hyperparameters: {best_lgb.get_params()}\\n\")\n",
    "\n",
    "print(f\"Model and metadata saved in {model_directory}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_edit_ss = df_edit[(df_edit.speedSet == 8.33203125) & (df_edit.load_value == 80)]\n",
    "\n",
    "df_edit_ss = df_edit_ss[(df_edit_ss.state_expected == 0) | (df_edit_ss.state_expected == 1)].copy()\n",
    "\n",
    "df_edit_ss.sort_values(by = ['state_expected'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop time normaliz\n",
    "df_edit_ss['sensor1_25_max'] = df_edit_ss['sensor1'].rolling(window=25, min_periods=1).max()\n",
    "df_edit_ss['sensor1_25_min'] = df_edit_ss['sensor1'].rolling(window=25, min_periods=1).min()\n",
    "df_edit_ss['sensor1_25_mean'] = df_edit_ss['sensor1'].rolling(window=25, min_periods=1).mean()\n",
    "df_edit_ss['sensor1_25_std'] = df_edit_ss['sensor1'].rolling(window=25, min_periods=1).std()\n",
    "df_edit_ss['sensor1_25_median'] = df_edit_ss['sensor1'].rolling(window=25, min_periods=1).median()\n",
    "\n",
    "df_edit_ss['sensor2_25_max'] = df_edit_ss['sensor2'].rolling(window=25, min_periods=1).max()\n",
    "df_edit_ss['sensor2_25_min'] = df_edit_ss['sensor2'].rolling(window=25, min_periods=1).min()\n",
    "df_edit_ss['sensor2_25_mean'] = df_edit_ss['sensor2'].rolling(window=25, min_periods=1).mean()\n",
    "df_edit_ss['sensor2_25_std'] = df_edit_ss['sensor2'].rolling(window=25, min_periods=1).std()\n",
    "df_edit_ss['sensor2_25_median'] = df_edit_ss['sensor2'].rolling(window=25, min_periods=1).median()\n",
    "\n",
    "df_edit_ss['sensor1_50_max'] = df_edit_ss['sensor1'].rolling(window=50, min_periods=1).max()\n",
    "df_edit_ss['sensor1_50_min'] = df_edit_ss['sensor1'].rolling(window=50, min_periods=1).min()\n",
    "df_edit_ss['sensor1_50_mean'] = df_edit_ss['sensor1'].rolling(window=50, min_periods=1).mean()\n",
    "df_edit_ss['sensor1_50_std'] = df_edit_ss['sensor1'].rolling(window=50, min_periods=1).std()\n",
    "df_edit_ss['sensor1_50_median'] = df_edit_ss['sensor1'].rolling(window=50, min_periods=1).median()\n",
    "\n",
    "df_edit_ss['sensor2_50_max'] = df_edit_ss['sensor2'].rolling(window=50, min_periods=1).max()\n",
    "df_edit_ss['sensor2_50_min'] = df_edit_ss['sensor2'].rolling(window=50, min_periods=1).min()\n",
    "df_edit_ss['sensor2_50_mean'] = df_edit_ss['sensor2'].rolling(window=50, min_periods=1).mean()\n",
    "df_edit_ss['sensor2_50_std'] = df_edit_ss['sensor2'].rolling(window=50, min_periods=1).std()\n",
    "df_edit_ss['sensor2_50_median'] = df_edit_ss['sensor2'].rolling(window=50, min_periods=1).median()\n",
    "\n",
    "df_edit_ss['sensor1_100_max'] = df_edit_ss['sensor1'].rolling(window=100, min_periods=1).max()\n",
    "df_edit_ss['sensor1_100_min'] = df_edit_ss['sensor1'].rolling(window=100, min_periods=1).min()\n",
    "df_edit_ss['sensor1_100_mean'] = df_edit_ss['sensor1'].rolling(window=100, min_periods=1).mean()\n",
    "df_edit_ss['sensor1_100_std'] = df_edit_ss['sensor1'].rolling(window=100, min_periods=1).std()\n",
    "df_edit_ss['sensor1_100_median'] = df_edit_ss['sensor1'].rolling(window=100, min_periods=1).median()\n",
    "\n",
    "df_edit_ss['sensor2_100_max'] = df_edit_ss['sensor2'].rolling(window=100, min_periods=1).max()\n",
    "df_edit_ss['sensor2_100_min'] = df_edit_ss['sensor2'].rolling(window=100, min_periods=1).min()\n",
    "df_edit_ss['sensor2_100_mean'] = df_edit_ss['sensor2'].rolling(window=100, min_periods=1).mean()\n",
    "df_edit_ss['sensor2_100_std'] = df_edit_ss['sensor2'].rolling(window=100, min_periods=1).std()\n",
    "df_edit_ss['sensor2_100_median'] = df_edit_ss['sensor2'].rolling(window=100, min_periods=1).median()\n",
    "\n",
    "df_edit_ss['sensor1_200_max'] = df_edit_ss['sensor1'].rolling(window=200, min_periods=1).max()\n",
    "df_edit_ss['sensor1_200_min'] = df_edit_ss['sensor1'].rolling(window=200, min_periods=1).min()\n",
    "df_edit_ss['sensor1_200_mean'] = df_edit_ss['sensor1'].rolling(window=200, min_periods=1).mean()\n",
    "df_edit_ss['sensor1_200_std'] = df_edit_ss['sensor1'].rolling(window=200, min_periods=1).std()\n",
    "df_edit_ss['sensor1_200_median'] = df_edit_ss['sensor1'].rolling(window=200, min_periods=1).median()\n",
    "\n",
    "df_edit_ss['sensor2_200_max'] = df_edit_ss['sensor2'].rolling(window=200, min_periods=1).max()\n",
    "df_edit_ss['sensor2_200_min'] = df_edit_ss['sensor2'].rolling(window=200, min_periods=1).min()\n",
    "df_edit_ss['sensor2_200_mean'] = df_edit_ss['sensor2'].rolling(window=200, min_periods=1).mean()\n",
    "df_edit_ss['sensor2_200_std'] = df_edit_ss['sensor2'].rolling(window=200, min_periods=1).std()\n",
    "df_edit_ss['sensor2_200_median'] = df_edit_ss['sensor2'].rolling(window=200, min_periods=1).median()\n",
    "\n",
    "df_edit_ss['sensor1_400_max'] = df_edit_ss['sensor1'].rolling(window=400, min_periods=1).max()\n",
    "df_edit_ss['sensor1_400_min'] = df_edit_ss['sensor1'].rolling(window=400, min_periods=1).min()\n",
    "df_edit_ss['sensor1_400_mean'] = df_edit_ss['sensor1'].rolling(window=400, min_periods=1).mean()\n",
    "df_edit_ss['sensor1_400_std'] = df_edit_ss['sensor1'].rolling(window=400, min_periods=1).std()\n",
    "df_edit_ss['sensor1_400_median'] = df_edit_ss['sensor1'].rolling(window=400, min_periods=1).median()\n",
    "\n",
    "df_edit_ss['sensor2_400_max'] = df_edit_ss['sensor2'].rolling(window=400, min_periods=1).max()\n",
    "df_edit_ss['sensor2_400_min'] = df_edit_ss['sensor2'].rolling(window=400, min_periods=1).min()\n",
    "df_edit_ss['sensor2_400_mean'] = df_edit_ss['sensor2'].rolling(window=400, min_periods=1).mean()\n",
    "df_edit_ss['sensor2_400_std'] = df_edit_ss['sensor2'].rolling(window=400, min_periods=1).std()\n",
    "df_edit_ss['sensor2_400_median'] = df_edit_ss['sensor2'].rolling(window=400, min_periods=1).median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_edit_ss_y = df_edit_ss.state_expected\n",
    "df_edit_ss_x = df_edit_ss.drop(columns = ['state_expected', 'time_normalized', 'sample'])\n",
    "\n",
    "# standardize the x\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df_edit_ss_x = scaler.fit_transform(df_edit_ss_x)\n",
    "\n",
    "df_edit_ss_predict = best_lgb.predict(df_edit_ss_x)\n",
    "\n",
    "df_edit_ss['predicted'] = df_edit_ss_predict\n",
    "df_edit_ss['indexer'] = df_edit_ss.reset_index(drop = True).index * 0.0002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_edit_ss['good_prediction'] = df_edit_ss.predicted == df_edit_ss.state_expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_edit_ss.predicted.value_counts()\n",
    "\n",
    "# make predicted2 column, whne predicted is > 0 then return 1\n",
    "df_edit_ss['predicted2'] = np.where(df_edit_ss['predicted'] > 0, 1, 0)\n",
    "df_edit_ss['good_prediction2'] = df_edit_ss.predicted2 == df_edit_ss.state_expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_edit_ss['good_prediction2'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2943*0.0002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from plotnine import ggplot, aes, geom_point, geom_line\n",
    "\n",
    "# Plot\n",
    "plot = (\n",
    "    ggplot(df_edit_ss, aes(x='indexer'))\n",
    "    + geom_point(aes(y = 'state_expected', color='factor(predicted2)'), alpha=0.5)  # Original data points\n",
    "    + geom_vline(aes(xintercept = 5.5886))\n",
    ")\n",
    "\n",
    "print(plot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_first_above_threshold(df, window_size, threshold=0.95):\n",
    "    \"\"\"\n",
    "    Identifies the first index where the rolling average of 'predicted2' exceeds a specified threshold.\n",
    "    \n",
    "    :param df: DataFrame containing the 'predicted2' column with prediction outcomes.\n",
    "    :param window_size: Size of the rolling window to calculate the average.\n",
    "    :param threshold: The threshold for the rolling average to identify the stopping point.\n",
    "    :return: The 'indexer' value at the first point where the condition is met.\n",
    "    \"\"\"\n",
    "    # Calculate the rolling average of predicted outcomes\n",
    "    rolling_avg = df['predicted2'].rolling(window=window_size).mean()\n",
    "\n",
    "    # Find the first index where the rolling average exceeds the threshold\n",
    "    first_above_threshold = rolling_avg > threshold\n",
    "    if first_above_threshold.any():\n",
    "        first_index = first_above_threshold.idxmax()\n",
    "        return df['indexer'][first_index]\n",
    "    else:\n",
    "        return None  # No point exceeds the threshold\n",
    "\n",
    "# Example DataFrame setup\n",
    "# df['predicted2'] should contain the probabilities or binary outcomes (1 or 0)\n",
    "# df['indexer'] should be set up with the time or index values\n",
    "\n",
    "# Usage\n",
    "window_size = 500  # For example, check over 10 consecutive predictions\n",
    "threshold_point = find_first_above_threshold(df_edit_ss, window_size)\n",
    "if threshold_point is not None:\n",
    "    print(f\"Early stopping point at indexer: {threshold_point}\")\n",
    "else:\n",
    "    print(\"No point exceeds the threshold within the given window.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(data = df_edit_ss, mapping = aes(x = 'indexer', y = 'predicted2', color = 'good_prediction2')) + geom_point(alpha = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Trasnform classes from numerical to names in someway\n",
    "predicted_names = [mapping_dict[label] for label in best_lgb.classes_]\n",
    "# Show confnusion matrix as a heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=predicted_names, yticklabels=predicted_names)\n",
    "plt.xlabel('Predikované')\n",
    "plt.ylabel('Aktuálne')\n",
    "plt.title(f'Konfúzna matica LightGBM, Val Acc: {accuracy_lgb:.2f}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfer = y_test.reset_index(drop=True).to_frame()\n",
    "dfer['time'] = X_test_not_scaled.time_normalized.reset_index(drop=True)\n",
    "dfer['state'] = y_pred\n",
    "dfer['yval'] = y_test.reset_index(drop=True)\n",
    "dfer['range'] = dfer.index\n",
    "dfer['good_prediction'] = (dfer.state == dfer.yval).astype(int)\n",
    "\n",
    "# Assuming 'time' is your feature and 'good_prediction' is the binary outcome\n",
    "X = dfer[['time']].values  # Features need to be 2D for scikit-learn\n",
    "y = dfer['good_prediction'].values  # Target variable\n",
    "\n",
    "# Fit the logistic regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "# Generate a range of x-values for predictions\n",
    "x_range = np.linspace(dfer['time'].min(), dfer['time'].max(), 300).reshape(-1, 1)\n",
    "\n",
    "# Predict probabilities for the generated x-values\n",
    "y_pred = model.predict_proba(x_range)[:, 1]  # Get probabilities for the positive class\n",
    "\n",
    "from plotnine import ggplot, aes, geom_point, geom_line, ggtitle\n",
    "\n",
    "# Original data points\n",
    "original_plot = (ggplot(dfer, aes(x='time', y='good_prediction', color='factor(good_prediction)')) +\n",
    "                 geom_point() +\n",
    "                 ggtitle('Predikcia LightGBM'))\n",
    "\n",
    "# Create a DataFrame for the logistic curve\n",
    "logistic_df = pd.DataFrame({'time': x_range.flatten(), 'probability': y_pred})\n",
    "\n",
    "# Add the logistic curve to the plot\n",
    "logistic_plot = (original_plot +\n",
    "                 geom_line(data=logistic_df, mapping=aes(x='time', y='probability'), color='red'))\n",
    "\n",
    "logistic_plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create XGB Classifier\n",
    "param_grid_xgb = {\n",
    "    'max_depth': [31],\n",
    "    'min_child_weight': [0.001],\n",
    "    'colsample_bytree': [1.0],\n",
    "    'learning_rate': [0.1],\n",
    "    'n_estimators': [100]\n",
    "}\n",
    "\n",
    "# Setup the model\n",
    "xgb_model = xgb.XGBClassifier()\n",
    "\n",
    "start_time3 = time()\n",
    "grid_search_xgb = GridSearchCV(xgb_model, param_grid_xgb, cv=4, verbose=1, scoring='accuracy', n_jobs=-1)\n",
    "# Pick the best model\n",
    "grid_search_xgb.fit(X_train, y_train)\n",
    "training_time = time() - start_time3\n",
    "best_xgb = best_lgb_model.best_estimator_\n",
    "time_test3 = time()\n",
    "# Predict the test set\n",
    "y_pred = best_xgb.predict(X_test)\n",
    "test_times.append(time() - time_test3)\n",
    "# Calculate the accuracy\n",
    "accuracy_xgb = accuracy_score(y_test, y_pred)\n",
    "display(print(\"Accuracy:\", accuracy_xgb))\n",
    "\n",
    "# Print the validation accuracy\n",
    "print(f'Validation Accuracy for LightGBM: {accuracy_xgb}')\n",
    "\n",
    "# Save the model to a file\n",
    "model_name = f'xgboost_{accuracy_xgb:.4f}'\n",
    "model_directory = 'models'\n",
    "model_path = f'{model_directory}/{model_name}.h5'\n",
    "joblib.dump(best_xgb, model_path)\n",
    "\n",
    "# Save the metadata\n",
    "metadata_path = f'{model_directory}/{model_name}_metadata.txt'\n",
    "with open(metadata_path, 'w') as f:\n",
    "    f.write(f\"Model Name: {model_name}\\n\")\n",
    "    f.write(f\"Accuracy: {accuracy_xgb}\\n\")\n",
    "    f.write(f\"Training Time: {training_time} seconds\\n\")\n",
    "    f.write(f\"Hyperparameters: {best_xgb.get_params()}\\n\")\n",
    "\n",
    "print(f\"Model and metadata saved in {model_directory}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Trasnform classes from numerical to names using state_expected_keys\n",
    "predicted_names = [mapping_dict[label] for label in best_xgb.classes_]\n",
    "\n",
    "# Show confnusion matrix as a heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=predicted_names, yticklabels=predicted_names)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title(f'Confusion matrix XGBoost, Val Acc: {accuracy_xgb:.2f}')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfer = y_test.reset_index(drop=True).to_frame()\n",
    "dfer['time'] = X_test_not_scaled.time_normalized.reset_index(drop=True)\n",
    "dfer['state'] = y_pred\n",
    "dfer['yval'] = y_test.reset_index(drop=True)\n",
    "dfer['range'] = dfer.index\n",
    "dfer['good_prediction'] = (dfer.state == dfer.yval).astype(int)\n",
    "\n",
    "# Assuming 'time' is your feature and 'good_prediction' is the binary outcome\n",
    "X = dfer[['time']].values  # Features need to be 2D for scikit-learn\n",
    "y = dfer['good_prediction'].values  # Target variable\n",
    "\n",
    "# Fit the logistic regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "# Generate a range of x-values for predictions\n",
    "x_range = np.linspace(dfer['time'].min(), dfer['time'].max(), 300).reshape(-1, 1)\n",
    "\n",
    "# Predict probabilities for the generated x-values\n",
    "y_pred = model.predict_proba(x_range)[:, 1]  # Get probabilities for the positive class\n",
    "\n",
    "from plotnine import ggplot, aes, geom_point, geom_line, ggtitle\n",
    "\n",
    "# Original data points\n",
    "original_plot = (ggplot(dfer, aes(x='time', y='good_prediction', color='factor(good_prediction)')) +\n",
    "                 geom_point() +\n",
    "                 ggtitle('Predikcia LightGBM'))\n",
    "\n",
    "# Create a DataFrame for the logistic curve\n",
    "logistic_df = pd.DataFrame({'time': x_range.flatten(), 'probability': y_pred})\n",
    "\n",
    "# Add the logistic curve to the plot\n",
    "logistic_plot = (original_plot +\n",
    "                 geom_line(data=logistic_df, mapping=aes(x='time', y='probability'), color='red'))\n",
    "\n",
    "logistic_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100],\n",
    "    'max_features': ['sqrt'],\n",
    "    'max_depth': [10],\n",
    "    'min_samples_split': [5],\n",
    "    'min_samples_leaf': [1]\n",
    "}\n",
    "\n",
    "# Setup the model\n",
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "start_time5 = time()\n",
    "# Pick the best model\n",
    "best_rf_model = GridSearchCV(rf_model, param_grid_rf, cv=4, verbose=1, n_jobs=-1)\n",
    "best_rf_model.fit(X_train, y_train)\n",
    "start_time = time() - start_time5\n",
    "\n",
    "best_rf = best_rf_model.best_estimator_\n",
    "time_test5 = time()\n",
    "# Predict the test set\n",
    "y_pred = best_rf.predict(X_test)\n",
    "test_times.append(time() - time_test5)\n",
    "# Calculate the accuracy\n",
    "accuracy_rf = accuracy_score(y_test, y_pred)\n",
    "display(print(\"Accuracy:\", accuracy_rf))\n",
    "\n",
    "# Print the validation accuracy\n",
    "print(f'Validation Accuracy for RandomForest: {accuracy_rf}')\n",
    "\n",
    "# Save the model to a file\n",
    "model_name = f'random_forest_{accuracy_rf:.4f}'\n",
    "model_directory = 'models'\n",
    "model_path = f'{model_directory}/{model_name}.h5'\n",
    "joblib.dump(best_rf, model_path)\n",
    "\n",
    "# Save the metadata\n",
    "metadata_path = f'{model_directory}/{model_name}_metadata.txt'\n",
    "with open(metadata_path, 'w') as f:\n",
    "    f.write(f\"Model Name: {model_name}\\n\")\n",
    "    f.write(f\"Accuracy: {accuracy_rf}\\n\")\n",
    "    f.write(f\"Training Time: {training_time} seconds\\n\")\n",
    "    f.write(f\"Hyperparameters: {best_rf.get_params()}\\n\")\n",
    "\n",
    "print(f\"Model and metadata saved in {model_directory}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Trasnform classes from numerical to names using state_expected_keys\n",
    "predicted_names = [mapping_dict[label] for label in best_rf.classes_]\n",
    "\n",
    "# Show confnusion matrix as a heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=predicted_names, yticklabels=predicted_names)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title(f'Confusion matrix RandomForest, Val Acc: {accuracy_rf:.2f}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression plot \n",
    "dfer = y_test.reset_index(drop=True).to_frame()\n",
    "dfer['time'] = X_test_not_scaled.time_normalized.reset_index(drop=True)\n",
    "dfer['state'] = y_pred\n",
    "dfer['yval'] = y_test.reset_index(drop=True)\n",
    "dfer['range'] = dfer.index\n",
    "dfer['good_prediction'] = (dfer.state == dfer.yval).astype(int)\n",
    "\n",
    "# Assuming 'time' is your feature and 'good_prediction' is the binary outcome\n",
    "X = dfer[['time']].values  # Features need to be 2D for scikit-learn\n",
    "y = dfer['good_prediction'].values  # Target variable\n",
    "\n",
    "# Fit the logistic regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "# Generate a range of x-values for predictions\n",
    "x_range = np.linspace(dfer['time'].min(), dfer['time'].max(), 300).reshape(-1, 1)\n",
    "\n",
    "# Predict probabilities for the generated x-values\n",
    "y_pred = model.predict_proba(x_range)[:, 1]  # Get probabilities for the positive class\n",
    "\n",
    "from plotnine import ggplot, aes, geom_point, geom_line, ggtitle\n",
    "\n",
    "# Original data points\n",
    "original_plot = (ggplot(dfer, aes(x='time', y='good_prediction', color='good_prediction') +\n",
    "                 geom_point() +\n",
    "                 ggtitle('Predikcia RF')))\n",
    "\n",
    "# Create a DataFrame for the logistic curve\n",
    "logistic_df = pd.DataFrame({'time': x_range.flatten(), 'probability': y_pred})\n",
    "\n",
    "# Add the logistic curve to the plot\n",
    "logistic_plot = (original_plot +\n",
    "                 geom_line(data=logistic_df, mapping=aes(x='time', y='probability'), color='red'))\n",
    "\n",
    "logistic_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a decision tree model for classification using the df dataset print the accuracy of the model\n",
    "param_grid_dt = {\n",
    "    'max_depth': [30],\n",
    "    'min_samples_split': [2],\n",
    "    'min_samples_leaf': [5]\n",
    "}\n",
    "\n",
    "# Setup the model\n",
    "dt_model = DecisionTreeClassifier()\n",
    "\n",
    "start_time6 = time()\n",
    "# Pick the best model\n",
    "best_dt_model = GridSearchCV(dt_model, param_grid_dt, cv=4, verbose=1, n_jobs=-1)\n",
    "best_dt_model.fit(X_train, y_train)\n",
    "start_time = time() - start_time6\n",
    "\n",
    "best_dt = best_dt_model.best_estimator_\n",
    "time_test6 = time()\n",
    "# Predict the test set\n",
    "y_pred = best_dt.predict(X_test)\n",
    "test_times.append(time() - time_test6)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy_dt = accuracy_score(y_test, y_pred)\n",
    "display(print(\"Accuracy:\", accuracy_dt))\n",
    "\n",
    "# Print the validation accuracy\n",
    "print(f'Validation Accuracy for DecisionTree: {accuracy_dt}')\n",
    "\n",
    "# Save the model to a file\n",
    "model_name = f'decision_tree_{accuracy_dt:.4f}'\n",
    "model_directory = 'models'\n",
    "model_path = f'{model_directory}/{model_name}.h5'\n",
    "joblib.dump(best_dt, model_path)\n",
    "\n",
    "# Save the metadata\n",
    "metadata_path = f'{model_directory}/{model_name}_metadata.txt'\n",
    "with open(metadata_path, 'w') as f:\n",
    "    f.write(f\"Model Name: {model_name}\\n\")\n",
    "    f.write(f\"Accuracy: {accuracy_dt}\\n\")\n",
    "    f.write(f\"Training Time: {training_time} seconds\\n\")\n",
    "    f.write(f\"Hyperparameters: {best_dt.get_params()}\\n\")\n",
    "\n",
    "print(f\"Model and metadata saved in {model_directory}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Trasnform classes from numerical to names using state_expected_keys\n",
    "predicted_names = [mapping_dict[label] for label in best_dt_model.classes_]\n",
    "\n",
    "# Show confnusion matrix as a heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=predicted_names, yticklabels=predicted_names)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title(f'Confusion matrix DecisionTree, Val Acc: {accuracy_dt:.2f}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfer = y_test.reset_index(drop=True).to_frame()\n",
    "dfer['time'] = X_test_not_scaled.time_normalized.reset_index(drop=True)\n",
    "dfer['state'] = y_pred\n",
    "dfer['yval'] = y_test.reset_index(drop=True)\n",
    "dfer['range'] = dfer.index\n",
    "dfer['good_prediction'] = (dfer.state == dfer.yval).astype(int)\n",
    "\n",
    "# Assuming 'time' is your feature and 'good_prediction' is the binary outcome\n",
    "X = dfer[['time']].values  # Features need to be 2D for scikit-learn\n",
    "y = dfer['good_prediction'].values  # Target variable\n",
    "\n",
    "# Fit the logistic regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "# Generate a range of x-values for predictions\n",
    "x_range = np.linspace(dfer['time'].min(), dfer['time'].max(), 300).reshape(-1, 1)\n",
    "\n",
    "# Predict probabilities for the generated x-values\n",
    "y_pred = model.predict_proba(x_range)[:, 1]  # Get probabilities for the positive class\n",
    "\n",
    "\n",
    "from plotnine import ggplot, aes, geom_point, geom_line, ggtitle\n",
    "\n",
    "# Original data points\n",
    "original_plot = (ggplot(dfer, aes(x='time', y='good_prediction', color='good_prediction') +\n",
    "                 geom_point() +\n",
    "                 ggtitle('Predikcia DT')))\n",
    "\n",
    "# Create a DataFrame for the logistic curve\n",
    "logistic_df = pd.DataFrame({'time': x_range.flatten(), 'probability': y_pred})\n",
    "\n",
    "# Add the logistic curve to the plot\n",
    "logistic_plot = (original_plot +\n",
    "                 geom_line(data=logistic_df, mapping=aes(x='time', y='probability'), color='red'))\n",
    "\n",
    "logistic_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a multilayer perceptron model for classification using the df dataset print the accuracy of the model\n",
    "param_distributions_mlp = {\n",
    "    'hidden_layer_sizes': [(150,), (160,)],\n",
    "    'activation': ['relu'],\n",
    "    'solver': ['adam'],\n",
    "    'alpha': [0.05],\n",
    "    'learning_rate': ['adaptive'],\n",
    "}\n",
    "\n",
    "# Setup the model\n",
    "mlp_model = MLPClassifier()\n",
    "\n",
    "start_time8 = time()\n",
    "grid_search_mlp = GridSearchCV(mlp_model, param_distributions_mlp, cv=4, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "# Pick the best model\n",
    "best_mlp_model = grid_search_mlp.fit(X_train, y_train)\n",
    "training_time = time() - start_time8\n",
    "\n",
    "best_mlp = best_mlp_model.best_estimator_\n",
    "time_test8 = time()\n",
    "# Predict the test set\n",
    "y_pred = best_mlp.predict(X_test)\n",
    "test_times.append(time() - time_test8)\n",
    "# Calculate the accuracy\n",
    "accuracy_mlp = accuracy_score(y_test, y_pred)\n",
    "display(print(\"Accuracy:\", accuracy_mlp))\n",
    "\n",
    "# Save the model to a file\n",
    "model_name = f'mlp_{accuracy_mlp:.4f}'\n",
    "model_directory = 'models'\n",
    "model_path = f'{model_directory}/{model_name}.h5'\n",
    "joblib.dump(best_mlp, model_path)\n",
    "\n",
    "# Save the metadata\n",
    "metadata_path = f'{model_directory}/{model_name}_metadata.txt'\n",
    "with open(metadata_path, 'w') as f:\n",
    "    f.write(f\"Model Name: {model_name}\\n\")\n",
    "    f.write(f\"Accuracy: {accuracy_mlp}\\n\")\n",
    "    f.write(f\"Training Time: {training_time} seconds\\n\")\n",
    "    f.write(f\"Hyperparameters: {best_mlp.get_params()}\\n\")\n",
    "\n",
    "print(f\"Model and metadata saved in {model_directory}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print mlp architecture\n",
    "print(best_mlp.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Trasnform classes from numerical to names using state_expected_keys\n",
    "predicted_names = [mapping_dict[label] for label in best_mlp.classes_]\n",
    "\n",
    "# Show confnusion matrix as a heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=predicted_names, yticklabels=predicted_names)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title(f'Confusion matrix MLP, Val Acc: {accuracy_mlp:.2f}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfer = y_test.reset_index(drop=True).to_frame()\n",
    "dfer['time'] = X_test_not_scaled.time_normalized.reset_index(drop=True)\n",
    "dfer['state'] = y_pred\n",
    "dfer['yval'] = y_test.reset_index(drop=True)\n",
    "dfer['range'] = dfer.index\n",
    "dfer['good_prediction'] = (dfer.state == dfer.yval).astype(int)\n",
    "\n",
    "# Assuming 'time' is your feature and 'good_prediction' is the binary outcome\n",
    "X = dfer[['time']].values  # Features need to be 2D for scikit-learn\n",
    "y = dfer['good_prediction'].values  # Target variable\n",
    "\n",
    "# Fit the logistic regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "# Generate a range of x-values for predictions\n",
    "x_range = np.linspace(dfer['time'].min(), dfer['time'].max(), 300).reshape(-1, 1)\n",
    "\n",
    "# Predict probabilities for the generated x-values\n",
    "y_pred = model.predict_proba(x_range)[:, 1]  # Get probabilities for the positive class\n",
    "\n",
    "from plotnine import ggplot, aes, geom_point, geom_line, ggtitle\n",
    "\n",
    "# Original data points\n",
    "original_plot = (ggplot(dfer, aes(x='time', y='good_prediction', color='good_prediction') +\n",
    "                 geom_point() +\n",
    "                 ggtitle('Predikcia MLP')))\n",
    "\n",
    "# Create a DataFrame for the logistic curve\n",
    "logistic_df = pd.DataFrame({'time': x_range.flatten(), 'probability': y_pred})\n",
    "\n",
    "# Add the logistic curve to the plot\n",
    "logistic_plot = (original_plot +\n",
    "                 geom_line(data=logistic_df, mapping=aes(x='time', y='probability'), color='red'))\n",
    "\n",
    "logistic_plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the best models trained so far and print their names and validation accuracies and do feature importance the model\n",
    "# with the highest validation accuracy\n",
    "import shap\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "models = {\n",
    "    'lightGBM': accuracy_lgb,\n",
    "    'xgboost': accuracy_xgb,\n",
    "    #'knn': accuracy_knn,\n",
    "    'random_forest': accuracy_rf,\n",
    "    'decision_tree': accuracy_dt,\n",
    "    #'svm': accuracy_svm,\n",
    "    'mlp': accuracy_mlp,\n",
    "}\n",
    "\n",
    "# Find the best model\n",
    "best_model_name = max(models, key=models.get)\n",
    "best_model_accuracy = models[best_model_name]\n",
    "\n",
    "print(f'Best model: {best_model_name}, Validation Accuracy: {best_model_accuracy}')\n",
    "\n",
    "# Load the best model\n",
    "best_model_path = f'models/{best_model_name}_{best_model_accuracy:.4f}.h5'\n",
    "best_model = joblib.load(best_model_path)\n",
    "\n",
    "# Feature importance\n",
    "# If knn then we do it differently\n",
    "if best_model_name == 'knn':\n",
    "    # Perform permutation importance\n",
    "    feature_imp = permutation_importance(best_model, X_test, y_test, n_repeats=1, random_state=42, n_jobs=-1)\n",
    "    sorted_idx = feature_imp.importances_mean.argsort()\n",
    "    plt.barh(X_test_not_scaled.columns[sorted_idx], feature_imp.importances_mean[sorted_idx])\n",
    "    plt.xlabel(\"Permutation Importance\")\n",
    "    plt.show()\n",
    "# And if mlp then we do it differently\n",
    "elif best_model_name == 'mlp':\n",
    "    feature_imp = permutation_importance(best_model, X_test, y_test, n_repeats=1, random_state=42, n_jobs=-1)\n",
    "    sorted_idx = feature_imp.importances_mean.argsort()\n",
    "    plt.barh(X_test_not_scaled.columns[sorted_idx], feature_imp.importances_mean[sorted_idx])\n",
    "    plt.xlabel(\"Permutation Importance\")\n",
    "    plt.show()\n",
    "elif best_model_name == 'svm':\n",
    "    feature_imp = permutation_importance(best_model, X_test, y_test, n_repeats=1, random_state=42, n_jobs=-1)\n",
    "    sorted_idx = feature_imp.importances_mean.argsort()\n",
    "    plt.barh(X_test_not_scaled.columns[sorted_idx], feature_imp.importances_mean[sorted_idx])\n",
    "    plt.xlabel(\"Permutation Importance\")\n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "    feature_imp = best_model.feature_importances_\n",
    "\n",
    "    # Plot feature importance\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.barh(X_test_not_scaled.columns, feature_imp)\n",
    "    plt.xlabel('Importance')\n",
    "    plt.ylabel('Features')\n",
    "    plt.title(f'Feature Importance for {best_model_name} Model')\n",
    "    plt.gca().invert_yaxis()  # Invert the y-axis to have the most important feature on top\n",
    "    plt.show()\n",
    "    \n",
    "plt.savefig(f'plots/feature_importance_{best_model_name}_{best_model_accuracy:.4f}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform y_test arrays values where the number does not equals 0 to 1\n",
    "y_tests = np.where(y_test != 0, 1, 0)\n",
    "unique, counts = np.unique(y_tests, return_counts=True)\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "# Directory containing the models\n",
    "model_directory = 'models'\n",
    "models = os.listdir(model_directory)\n",
    "model_accuracies = {}\n",
    "\n",
    "for model in models:\n",
    "    if model.endswith('.h5'):\n",
    "        # Split the filename to isolate the parts\n",
    "        parts = model.rsplit('_', 1)  # This splits only at the last underscore\n",
    "        model_name = '_'.join(parts[:-1])  # Rejoin all but the last part for the full model name\n",
    "        accuracy_part = parts[-1].replace('.h5', '')  # The last part, without '.h5'\n",
    "        \n",
    "        try:\n",
    "            model_accuracy = float(accuracy_part)  # Convert the accuracy part to float\n",
    "            model_accuracies[model_name] = model_accuracy  # Store using model name\n",
    "        except ValueError:\n",
    "            print(f\"Could not convert {accuracy_part} to float for model {model}\")\n",
    "\n",
    "# Find the model with the highest accuracy\n",
    "if model_accuracies:\n",
    "    best_model_name, best_model_accuracy = max(model_accuracies.items(), key=lambda item: item[1])\n",
    "    print(f'Best model: {best_model_name}, Validation Accuracy: {best_model_accuracy}')\n",
    "else:\n",
    "    print(\"No valid model accuracies found.\")\n",
    "\n",
    "# Predict with the best model and evaluate, plot the confusion matrix and the ROC curve\n",
    "# Load the best model\n",
    "best_model_path = f'models/{best_model_name}_{best_model_accuracy:.4f}.h5'\n",
    "best_model = joblib.load(best_model_path)\n",
    "\n",
    "# Predict the test set\n",
    "y_preds = best_model.predict(X_test)\n",
    "y_preds = np.where(y_preds != 0, 1, 0)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_tests, y_preds)\n",
    "display(print(f'Accuracy: {accuracy:.4f}'))\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(y_tests, y_preds)\n",
    "\n",
    "# Show confnusion matrix as a heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['bez_poruchy', 'fault'], yticklabels=['bez_poruchy', 'fault'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title(f'Confusion matrix for {best_model_name}, Test Acc: {accuracy:.2f}')\n",
    "plt.show()\n",
    "plt.savefig(f'plots/confusion_matrix_{best_model_name}_{best_model_accuracy:.4f}.png')\n",
    "# Calculate the ROC curve\n",
    "y_pred_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "fpr, tpr, thresholds = roc_curve(y_tests, y_pred_proba)\n",
    "\n",
    "# Plot the ROC curve\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(fpr, tpr)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title(f'ROC Curve for {best_model_name}')\n",
    "plt.show()\n",
    "plt.savefig(f'plots/roc_curve_{best_model_name}_{best_model_accuracy:.4f}.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the prediction for the training set\n",
    "y_trains = np.where(y_train != 0, 1, 0)\n",
    "y_train_preds = best_model.predict(X_train)\n",
    "y_train_preds = np.where(y_train_preds != 0, 1, 0)\n",
    "# Calculate the accuracy\n",
    "accuracy_train = accuracy_score(y_trains, y_train_preds)\n",
    "display(print(f'Accuracy: {accuracy_train:.4f}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrix\n",
    "cm = confusion_matrix(y_trains, y_train_preds)\n",
    "\n",
    "# Show confnusion matrix as a heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['bez_poruchy', 'fault'], yticklabels=['bez_poruchy', 'fault'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title(f'Confusion matrix for {best_model_name}, Train Acc: {accuracy_train:.2f}')\n",
    "plt.show()\n",
    "plt.savefig(f'plots/confusion_matrix_train_{best_model_name}_{best_model_accuracy:.4f}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recall, Precision, F1-Score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(y_trains, y_train_preds))\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(y_tests, y_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge X_train_not_scaled and y_train and X_test_not_scaled and y_test and then together\n",
    "df_train = X_train_not_scaled.copy()\n",
    "df_train['state_expected'] = y_train\n",
    "df_test = X_test_not_scaled.copy()\n",
    "df_test['state_expected'] = y_test\n",
    "df_all = pd.concat([df_train, df_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order by state_expected and time_normalized\n",
    "df_all = df_all.sort_values(['state_expected', 'time_normalized']).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick state_expected column values where values equals 0\n",
    "df_bez_poruchy = df_all.loc[df_all['state_expected'] == 0]\n",
    "# Do it for other values 0 - 5 with for and create 6 unique datasets merged with the df_bez_poruchy \n",
    "for i in range(0, 6):\n",
    "    df_fault = df_all.loc[df_all['state_expected'] == i]\n",
    "    # Add 5 to time_normalized column values\n",
    "    df_fault['time_normalized'] = df_fault['time_normalized'] + 5\n",
    "    # Merge the 2 selected datasets to new datasets with new names without saving\n",
    "    df_new = pd.concat([df_bez_poruchy, df_fault])\n",
    "    # Save datasets\n",
    "    df_new.to_csv(f'datasets/df_new_{i}.csv', index=False)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "df_new_0 = pd.read_csv('datasets/df_new_0.csv')\n",
    "df_new_1 = pd.read_csv('datasets/df_new_1.csv')\n",
    "df_new_2 = pd.read_csv('datasets/df_new_2.csv')\n",
    "df_new_3 = pd.read_csv('datasets/df_new_3.csv')\n",
    "df_new_4 = pd.read_csv('datasets/df_new_4.csv')\n",
    "df_new_5 = pd.read_csv('datasets/df_new_5.csv')\n",
    "# Find and load lgb model with highest acc\n",
    "models = {\n",
    "    'lightGBM': accuracy_lgb,\n",
    "    'xgboost': accuracy_xgb,\n",
    "    #'knn': accuracy_knn,\n",
    "    'random_forest': accuracy_rf,\n",
    "    'decision_tree': accuracy_dt,\n",
    "    #'svm': accuracy_svm,\n",
    "    'mlp': accuracy_mlp,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find lgbm model with highest accuracy\n",
    "# Define the directory containing the models\n",
    "model_directory = 'models'  # Adjust path as needed\n",
    "best_model_path = None\n",
    "highest_accuracy = 0\n",
    "model_names = 'lightgbm_'\n",
    "\n",
    "# Iterate through each file in the directory\n",
    "for filename in os.listdir(model_directory):\n",
    "    if filename.startswith(model_names) and filename.endswith(\".h5\"):\n",
    "        # Extract accuracy from filename\n",
    "        accuracy = float(filename.split('_')[1].replace('.h5', ''))\n",
    "        if accuracy > highest_accuracy:\n",
    "            highest_accuracy = accuracy\n",
    "            best_model_path = os.path.join(model_directory, filename)\n",
    "\n",
    "# Load the best model if found\n",
    "if best_model_path:\n",
    "    model_resp = joblib.load(best_model_path)\n",
    "    print(f\"Best model loaded: {best_model_path} with accuracy {highest_accuracy}\")\n",
    "else:\n",
    "    print(\"No LightGBM model files found.\")\n",
    "\n",
    "# Dynamically predict the state_expected column values for each dataset and print the accuracy\n",
    "# Create a dictionary to hold the datasets\n",
    "datasets = {\n",
    "    'df_new_0': df_new_0,\n",
    "    'df_new_1': df_new_1,\n",
    "    'df_new_2': df_new_2,\n",
    "    'df_new_3': df_new_3,\n",
    "    'df_new_4': df_new_4,\n",
    "    'df_new_5': df_new_5\n",
    "}\n",
    "\n",
    "# Create a dictionary to hold the accuracies\n",
    "lgb_accuracies = {}\n",
    "pred_data = {}\n",
    "# Iterate over the datasets\n",
    "for name, dataset in datasets.items():\n",
    "    # Separate the features and target variable\n",
    "    X = dataset.drop(columns=['state_expected'])\n",
    "    y = dataset['state_expected']\n",
    "    # Use standardscaler on X\n",
    "    X = scaler.transform(X)\n",
    "    # Predict the target variable\n",
    "    lgb_y_pred = model_resp.predict(X)\n",
    "    \n",
    "    # Calculate the accuracy\n",
    "    accuracy = accuracy_score(y, lgb_y_pred)\n",
    "    lgb_accuracies[name] = accuracy\n",
    "    display(print(f'Accuracy for {name}: {accuracy:.4f}'))\n",
    "    # Save every iteration of predictions\n",
    "    pred_data[name + model_names] = lgb_y_pred\n",
    "\n",
    "    # DataFrame setup\n",
    "    dfer = y.reset_index(drop=True).to_frame(name='yval')\n",
    "    dfer['time'] = df_new_0['time_normalized'].reset_index(drop=True)\n",
    "    dfer['state'] = lgb_y_pred\n",
    "    dfer['range'] = dfer.index\n",
    "    dfer['good_prediction'] = (dfer['state'] == dfer['yval']).astype(int)\n",
    "\n",
    "    # Filter to keep only the middle 40% of the data\n",
    "    total_count = len(dfer)\n",
    "    lower_bound = int(total_count * 0.3)  # Adjust to 30%\n",
    "    upper_bound = int(total_count * 0.7)  # Adjust to 70%\n",
    "    dfer = dfer.loc[lower_bound:upper_bound]\n",
    "\n",
    "    # Prepare for logistic regression curve (must ensure this part makes sense for your analysis)\n",
    "    x_range = np.linspace(dfer['time'].min(), dfer['time'].max(), 300).reshape(-1, 1)\n",
    "    avg_roll = dfer['good_prediction'].rolling(window=int(len(dfer)*0.1), min_periods=1).mean()  # Adjust window size\n",
    "\n",
    "    # Plotting setup\n",
    "    original_plot = (ggplot(dfer, aes(x='time', y='good_prediction', color='good_prediction')\n",
    "                    + geom_point()\n",
    "                    + ggtitle('Reakcia')))\n",
    "\n",
    "    # Create a DataFrame for plotting - ensuring avg_roll matches x_range in length\n",
    "    logistic_df = pd.DataFrame({\n",
    "        'time': np.linspace(dfer['time'].min(), dfer['time'].max(), len(avg_roll)),\n",
    "        'probability': avg_roll\n",
    "    })\n",
    "\n",
    "    # Add the logistic curve to the plot\n",
    "    logistic_plot = (original_plot + \n",
    "                    geom_line(data=logistic_df, mapping=aes(x='time', y='probability'), color='red'))\n",
    "\n",
    "    print(logistic_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find lgbm model with highest accuracy\n",
    "# Define the directory containing the models\n",
    "model_directory = 'models'  # Adjust path as needed\n",
    "best_model_path = None\n",
    "highest_accuracy = 0\n",
    "xgb_accuracies = {}\n",
    "model_names = 'xgboost_'\n",
    "\n",
    "# Iterate through each file in the directory\n",
    "for filename in os.listdir(model_directory):\n",
    "    if filename.startswith(model_names) and filename.endswith(\".h5\"):\n",
    "        # Extract accuracy from filename\n",
    "        accuracy = float(filename.split('_')[1].replace('.h5', ''))\n",
    "        if accuracy > highest_accuracy:\n",
    "            highest_accuracy = accuracy\n",
    "            best_model_path = os.path.join(model_directory, filename)\n",
    "\n",
    "# Load the best model if found\n",
    "if best_model_path:\n",
    "    #best_model_path = f'models/{best_model_name}_{highest_accuracy:.4f}.h5'\n",
    "    model_resp = joblib.load(best_model_path)\n",
    "    print(f\"Best model loaded: {best_model_path} with accuracy {highest_accuracy}\")\n",
    "else:\n",
    "    print(\"No LightGBM model files found.\")\n",
    "# Iterate over the datasets\n",
    "for name, dataset in datasets.items():\n",
    "    # Separate the features and target variable\n",
    "    X = dataset.drop(columns=['state_expected'])\n",
    "    y = dataset['state_expected']\n",
    "    # Use standardscaler on X\n",
    "    X = scaler.transform(X)\n",
    "    # Predict the target variable\n",
    "    xgb_y_pred = model_resp.predict(X)\n",
    "    \n",
    "    # Calculate the accuracy\n",
    "    accuracy = accuracy_score(y, xgb_y_pred)\n",
    "    xgb_accuracies[name] = accuracy\n",
    "    display(print(f'Accuracy for {name}: {accuracy:.4f}'))\n",
    "    # Save every iteration of predictions\n",
    "    pred_data[name + model_names] = xgb_y_pred\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find lgbm model with highest accuracy\n",
    "# Define the directory containing the models\n",
    "model_directory = 'models'  # Adjust path as needed\n",
    "best_model_path = None\n",
    "highest_accuracy = 0\n",
    "rf_accuracies = {}\n",
    "model_names = 'random_forest_'\n",
    "\n",
    "for filename in os.listdir(model_directory):\n",
    "    if filename.startswith(model_names) and filename.endswith(\".h5\"):\n",
    "        # Correctly split the filename and extract the accuracy\n",
    "        parts = filename.split('_')\n",
    "        # Assuming the accuracy part is always the second last element before \".h5\"\n",
    "        accuracy_part = parts[-1].replace('.h5', '')\n",
    "        accuracy = float(accuracy_part)\n",
    "        if accuracy > highest_accuracy:\n",
    "            highest_accuracy = accuracy\n",
    "            best_model_path = os.path.join(model_directory, filename)\n",
    "\n",
    "# Load the best model if found\n",
    "if best_model_path:\n",
    "    #best_model_path = f'models/{best_model_name}_{highest_accuracy:.4f}.h5'\n",
    "    model_resp = joblib.load(best_model_path)\n",
    "    print(f\"Best model loaded: {best_model_path} with accuracy {highest_accuracy}\")\n",
    "else:\n",
    "    print(\"No LightGBM model files found.\")\n",
    "# Iterate over the datasets\n",
    "for name, dataset in datasets.items():\n",
    "    # Separate the features and target variable\n",
    "    X = dataset.drop(columns=['state_expected'])\n",
    "    y = dataset['state_expected']\n",
    "    # Use standardscaler on X\n",
    "    X = scaler.transform(X)\n",
    "    # Predict the target variable\n",
    "    rf_y_pred = model_resp.predict(X)\n",
    "    \n",
    "    # Calculate the accuracy\n",
    "    accuracy = accuracy_score(y, rf_y_pred)\n",
    "    rf_accuracies[name] = accuracy\n",
    "    display(print(f'Accuracy for {name}: {accuracy:.4f}'))\n",
    "    # Save every iteration of predictions\n",
    "    pred_data[name + model_names] = rf_y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find lgbm model with highest accuracy\n",
    "# Define the directory containing the models\n",
    "model_directory = 'models'  # Adjust path as needed\n",
    "best_model_path = None\n",
    "highest_accuracy = 0\n",
    "dt_accuracies = {}\n",
    "model_names = 'decision_tree_'\n",
    "\n",
    "for filename in os.listdir(model_directory):\n",
    "    if filename.startswith(model_names) and filename.endswith(\".h5\"):\n",
    "        # Correctly split the filename and extract the accuracy\n",
    "        parts = filename.split('_')\n",
    "        # Assuming the accuracy part is always the second last element before \".h5\"\n",
    "        accuracy_part = parts[-1].replace('.h5', '') \n",
    "        accuracy = float(accuracy_part)\n",
    "        if accuracy > highest_accuracy:\n",
    "            highest_accuracy = accuracy\n",
    "            best_model_path = os.path.join(model_directory, filename)\n",
    "\n",
    "# Load the best model if found\n",
    "if best_model_path:\n",
    "    #best_model_path = f'models/{best_model_name}_{highest_accuracy:.4f}.h5'\n",
    "    model_resp = joblib.load(best_model_path)\n",
    "    print(f\"Best model loaded: {best_model_path} with accuracy {highest_accuracy}\")\n",
    "else:\n",
    "    print(\"No LightGBM model files found.\")\n",
    "# Iterate over the datasets\n",
    "for name, dataset in datasets.items():\n",
    "    # Separate the features and target variable\n",
    "    X = dataset.drop(columns=['state_expected'])\n",
    "    y = dataset['state_expected']\n",
    "    # Use standardscaler on X\n",
    "    X = scaler.transform(X)\n",
    "    # Predict the target variable\n",
    "    dt_y_pred = model_resp.predict(X)\n",
    "    \n",
    "    # Calculate the accuracy\n",
    "    accuracy = accuracy_score(y, dt_y_pred)\n",
    "    dt_accuracies[name] = accuracy\n",
    "    display(print(f'Accuracy for {name}: {accuracy:.4f}'))\n",
    "    # Save every iteration of predictions\n",
    "    pred_data[name + model_names] = dt_y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find lgbm model with highest accuracy\n",
    "# Define the directory containing the models\n",
    "model_directory = 'models'  # Adjust path as needed\n",
    "best_model_path = None\n",
    "highest_accuracy = 0\n",
    "mlp_accuracies = {}\n",
    "model_names = 'mlp_'\n",
    "\n",
    "# Iterate through each file in the directory\n",
    "for filename in os.listdir(model_directory):\n",
    "    if filename.startswith(model_names) and filename.endswith(\".h5\"):\n",
    "        # Extract accuracy from filename\n",
    "        accuracy = float(filename.split('_')[1].replace('.h5', ''))\n",
    "        if accuracy > highest_accuracy:\n",
    "            highest_accuracy = accuracy\n",
    "            best_model_path = os.path.join(model_directory, filename)\n",
    "\n",
    "# Load the best model if found\n",
    "if best_model_path:\n",
    "    #best_model_path = f'models/{best_model_name}_{highest_accuracy:.4f}.h5'\n",
    "    model_resp = joblib.load(best_model_path)\n",
    "    print(f\"Best model loaded: {best_model_path} with accuracy {highest_accuracy}\")\n",
    "else:\n",
    "    print(\"No LightGBM model files found.\")\n",
    "# Iterate over the datasets\n",
    "for name, dataset in datasets.items():\n",
    "    # Separate the features and target variable\n",
    "    X = dataset.drop(columns=['state_expected'])\n",
    "    y = dataset['state_expected']\n",
    "    # Use standardscaler on X\n",
    "    X = scaler.transform(X)\n",
    "    # Predict the target variable\n",
    "    mlp_y_pred = model_resp.predict(X)\n",
    "    \n",
    "    # Calculate the accuracy\n",
    "    accuracy = accuracy_score(y, mlp_y_pred)\n",
    "    mlp_accuracies[name] = accuracy\n",
    "    display(print(f'Accuracy for {name}: {accuracy:.4f}'))\n",
    "    # Save every iteration of predictions\n",
    "    pred_data[name + model_names] = mlp_y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and avarage accuracy for each model and select the best one\n",
    "# Calculate the average accuracy for each model\n",
    "lgb_accuracies_avg = np.mean(list(lgb_accuracies.values()))\n",
    "xgb_accuracies_avg = np.mean(list(xgb_accuracies.values()))\n",
    "rf_accuracies_avg = np.mean(list(rf_accuracies.values()))\n",
    "dt_accuracies_avg = np.mean(list(dt_accuracies.values()))\n",
    "mlp_accuracies_avg = np.mean(list(mlp_accuracies.values()))\n",
    "\n",
    "# Create a dictionary to hold the average accuracies\n",
    "avg_accuracies = {\n",
    "    'lightGBM': lgb_accuracies_avg,\n",
    "    'xgboost': xgb_accuracies_avg,\n",
    "    'random_forest': rf_accuracies_avg,\n",
    "    'decision_tree': dt_accuracies_avg,\n",
    "    'mlp': mlp_accuracies_avg\n",
    "}\n",
    "\n",
    "# Find the model with the highest average accuracy\n",
    "best_model_name = max(avg_accuracies, key=avg_accuracies.get)\n",
    "best_model_accuracy = avg_accuracies[best_model_name]\n",
    "\n",
    "# Display model with the least test time from time_test\n",
    "best_model_time = min(test_times)\n",
    "display(print(f'Best model: {best_model_name}, Average Accuracy: {best_model_accuracy:.4f}'))\n",
    "\n",
    "# Now with the same with avarage accuracy\n",
    "lgb_accuracies_avgs = np.average(list(lgb_accuracies.values()))\n",
    "xgb_accuracies_avgs = np.average(list(xgb_accuracies.values()))\n",
    "#knn_accuracies_avgs = np.average(list(knn_accuracies.values())\n",
    "rf_accuracies_avgs = np.average(list(rf_accuracies.values()))\n",
    "dt_accuracies_avgs = np.average(list(dt_accuracies.values()))\n",
    "#svc_accuracies_avgs = np.average(list(svc_accuracies.values())\n",
    "mlp_accuracies_avgs = np.average(list(mlp_accuracies.values()))\n",
    "\n",
    "# Create a dictionary to hold the average accuracies\n",
    "avg_accuracies = {\n",
    "    'lightGBM': lgb_accuracies_avgs,\n",
    "    'xgboost': xgb_accuracies_avgs,\n",
    "    'random_forest': rf_accuracies_avgs,\n",
    "    'decision_tree': dt_accuracies_avgs,\n",
    "    'mlp': mlp_accuracies_avgs\n",
    "}\n",
    "\n",
    "# Find the model with the highest average accuracy\n",
    "best_model_name = max(avg_accuracies, key=avg_accuracies.get)\n",
    "best_model_accuracy = avg_accuracies[best_model_name]\n",
    "\n",
    "display(print(f'Best model: {best_model_name}, Average Accuracy: {best_model_accuracy:.4f}'))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(test_times)\n",
    "#lgb_accuracies_avgs = np.average(list(lgb_accuracies.values())\n",
    "#xgb_accuracies_avgs = np.average(list(xgb_accuracies.values())\n",
    "#knn_accuracies_avgs = np.average(list(knn_accuracies.values())\n",
    "#rf_accuracies_avgs = np.average(list(rf_accuracies.values())\n",
    "#dt_accuracies_avgs = np.average(list(dt_accuracies.values())\n",
    "#svc_accuracies_avgs = np.average(list(svc_accuracies.values())\n",
    "#mlp_accuracies_avgs = np.average(list(mlp_accuracies.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find lgbm model with highest accuracy\n",
    "# Define the directory containing the models\n",
    "model_directory = 'models'  # Adjust path as needed\n",
    "best_model_path = None\n",
    "highest_accuracy = 0\n",
    "model_names = 'lightgbm_'\n",
    "\n",
    "# Iterate through each file in the directory\n",
    "for filename in os.listdir(model_directory):\n",
    "    if filename.startswith(model_names) and filename.endswith(\".h5\"):\n",
    "        # Extract accuracy from filename\n",
    "        accuracy = float(filename.split('_')[1].replace('.h5', ''))\n",
    "        if accuracy > highest_accuracy:\n",
    "            highest_accuracy = accuracy\n",
    "            best_model_path = os.path.join(model_directory, filename)\n",
    "\n",
    "# Load the best model if found\n",
    "if best_model_path:\n",
    "    model_retr = joblib.load(best_model_path)\n",
    "    print(f\"Best model loaded: {best_model_path} with accuracy {highest_accuracy}\")\n",
    "else:\n",
    "    print(\"No LightGBM model files found.\")\n",
    "\n",
    "# Retrain model with the best model\n",
    "# Separate the features and target variable\n",
    "X = X_train\n",
    "y = y_train\n",
    "\n",
    "# Retrain the model\n",
    "model_retr.fit(X, y)\n",
    "\n",
    "# Print accuracy\n",
    "accuracy = accuracy_score(y, model_retr.predict(X))\n",
    "display(print(f'Accuracy: {accuracy:.4f}'))\n",
    "\n",
    "# Dynamically predict the state_expected column values for each dataset and print the accuracy\n",
    "# Transform df_new_2['state_expected'] values to 1 as only for the 2nd half of the dataset\n",
    "df_new_2['state_expected'] = np.where(df_new_1['state_expected'] != 0, 1, 0)\n",
    "df_new_3['state_expected'] = np.where(df_new_1['state_expected'] != 0, 1, 0)\n",
    "df_new_4['state_expected'] = np.where(df_new_1['state_expected'] != 0, 1, 0)\n",
    "df_new_5['state_expected'] = np.where(df_new_1['state_expected'] != 0, 1, 0)\n",
    "# Create a dictionary to hold the datasets\n",
    "datasets = {\n",
    "    'df_new_0': df_new_0,\n",
    "    'df_new_1': df_new_1,\n",
    "    'df_new_2': df_new_2,\n",
    "    'df_new_3': df_new_3,\n",
    "    'df_new_4': df_new_4,\n",
    "    'df_new_5': df_new_5\n",
    "}\n",
    "\n",
    "# Create a dictionary to hold the accuracies\n",
    "lgbs_accuracies = {}\n",
    "preds_data = {}\n",
    "# Iterate over the datasets\n",
    "for name, dataset in datasets.items():\n",
    "    # Separate the features and target variable\n",
    "    X = dataset.drop(columns=['state_expected'])\n",
    "    y = dataset['state_expected']\n",
    "    display(len(y))\n",
    "    # Use standardscaler on X\n",
    "    X = scaler.transform(X)\n",
    "    # Predict the target variable\n",
    "    lgb_y_pred = model_retr.predict(X)\n",
    "    display(len(lgb_y_pred))\n",
    "    # Where the number does not equals 0 to 1 for lgb_y_pred\n",
    "    lgb_y_pred = np.where(lgb_y_pred != 0, 1, 0)\n",
    "    # Calculate the accuracy\n",
    "    accuracy = accuracy_score(y, lgb_y_pred)\n",
    "    lgb_accuracies[name] = accuracy\n",
    "    display(print(f'Accuracy for {name}: {accuracy:.4f}'))\n",
    "    # Save every iteration of predictions\n",
    "    pred_data[name + model_names] = lgb_y_pred\n",
    "\n",
    "    # DataFrame setup\n",
    "    dfer = y.reset_index(drop=True).to_frame(name='yval')\n",
    "    dfer['time'] = df_new_0['time_normalized'].reset_index(drop=True)\n",
    "    dfer['state'] = lgb_y_pred\n",
    "    dfer['range'] = dfer.index\n",
    "    dfer['good_prediction'] = (dfer['state'] == dfer['yval']).astype(int)\n",
    "\n",
    "    # Filter to keep only the middle 40% of the data\n",
    "    total_count = len(dfer)\n",
    "    lower_bound = int(total_count * 0.3)  # Adjust to 30%\n",
    "    upper_bound = int(total_count * 0.7)  # Adjust to 70%\n",
    "    dfer = dfer.loc[lower_bound:upper_bound]\n",
    "\n",
    "    # Prepare for logistic regression curve (must ensure this part makes sense for your analysis)\n",
    "    x_range = np.linspace(dfer['time'].min(), dfer['time'].max(), 300).reshape(-1, 1)\n",
    "    avg_roll = dfer['good_prediction'].rolling(window=int(len(dfer)*0.1), min_periods=1).mean()  # Adjust window size\n",
    "\n",
    "    # Plotting setup\n",
    "    original_plot = (ggplot(dfer, aes(x='time', y='good_prediction', color='good_prediction')\n",
    "                    + geom_point()\n",
    "                    + ggtitle('Reakcia')))\n",
    "\n",
    "    # Create a DataFrame for plotting - ensuring avg_roll matches x_range in length\n",
    "    logistic_df = pd.DataFrame({\n",
    "        'time': np.linspace(dfer['time'].min(), dfer['time'].max(), len(avg_roll)),\n",
    "        'probability': avg_roll\n",
    "    })\n",
    "\n",
    "    # Add the logistic curve to the plot\n",
    "    logistic_plot = (original_plot + \n",
    "                    geom_line(data=logistic_df, mapping=aes(x='time', y='probability'), color='red'))\n",
    "\n",
    "    print(logistic_plot)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
